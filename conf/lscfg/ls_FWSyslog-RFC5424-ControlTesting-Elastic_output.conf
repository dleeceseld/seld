# Author Doug Leece  dleece @ firstfiretech dot ca 

# April/07/2023  Read RFC5424 formatted PFSense Event log source file into Elastic Index
#
# Anticipated logsource is a SELD deidentifed dataset from recent PFsense firewalls logging in RFC5424 format
# This logging format has the rule events in a single field using CSV which allows the use of the Logstash
# split function which is very efficient.
#
# PFSense firewall rule mapping and logging setup guidance can be found onthe PFSense website.
#  https://docs.netgate.com/pfsense/en/latest/monitoring/logs/raw-filter-format.html
#
# Testing guidance
# Resulting record counts for a given raw input should match exactly for valid control testing
# The Kibana platform should be used for content validation as row count is only one metric
#


# Modify path based on SELD home location, /opt/seld by default
input {
        file {
                path => "/opt/seld/rawlogs/fwsyslog.log*"
                mode => "read"
                file_completed_action => "log"
                file_completed_log_path => "/opt/seld/tmp/fwsyslog_processing.log"
                exit_after_read => true
                sincedb_path => "/opt/seld/fwsyslog_tracker"
                sincedb_clean_after => 0.00135
        }
} # End input

#####################################################################################################################################


# RFC5424 header elements all within GROK default pattern set, 

filter{
  grok{
    match => { 'message' => '^<%{POSINT:pri}>%{POSINT:version}%{SPACE}%{TIMESTAMP_ISO8601:[event][created]}%{SPACE}%{IPORHOST:host_name_orig}%{SPACE}%{WORD:[program][name]}%{SPACE}%{POSINT:[program][pid]}%{SPACE}-%{SPACE}-%{SPACE}%{GREEDYDATA:[rule][FWEvent]}$' }
  }
}

# Alternate regex for deidentified hostnames, some of the characters used in FPE don't work with the default pattern
filter {
  if "_grokparsefailure" in [tags]{
    grok{
      match => { 'message' => '^<%{POSINT:pri}>%{POSINT:version}%{SPACE}%{TIMESTAMP_ISO8601:[event][created]}%{SPACE}(?<host_name_deident>[_0-9A-Za-z\.-]*?)%{SPACE}%{WORD:[program][name]}%{SPACE}%{POSINT:[program][pid]}%{SPACE}-%{SPACE}-%{SPACE}%{GREEDYDATA:[rule][FWEvent]}$' } 
    }
  }
  if [host_name_deident] {
    mutate { add_tag => "seld_eventsourcehostname"}
    mutate { remove_tag => ["_grokparsefailure"]}
  }
}


# Modify or remove collection artifacts: 
# Overwrite the hostname from the log processor with the firewall hostname in log source, avoids confusion
filter {
  if [host_name_orig] {
    mutate{ rename =>{ "host_name_orig" => "[host][name]" }  }
  }
  if [host_name_deident] {
    mutate{ rename =>{ "host_name_deident" => "[host][name]" }  }
  }
} # End hostname clean up

# Force overwrite of the Logstash ingestion timestamp  - PFS sense uses 8601 format with microsecond precision, Logstash truncates to milli
filter {
  if [event][created] {
      date{
        match => ["[event][created]","ISO8601"]
        target => "@timestamp"
        add_tag => "timestamp_original"
      }
  }
}   # End timestamp processing filter


# Elastic ECS specific fields (meta data)
filter{
  mutate { add_field => { "[event][kind]" => "event"}}
  
}  # End collection artifact filter




##########################       Data transformation for Elastic indexing               ##############################################

# Add tags based on fields
# Extract hostname, and rule event portion of the message
filter {
  if [host][name] {
     mutate { add_tag => "fwsyslog_host"} 
  }
  if [progam][name] == "filterlog" {
    mutate { add_tag => "fwsyslog_filterlog"} 
  }
  if [rule][FWEvent] {
    mutate { add_tag => "fwsyslog_FWEvent"}
  }
}



##########################       PFSense field conversions to ECS Format       ##############################################

filter {
    # Attempting to split the PFsense CSV data into individual fields without parsing 
    if [rule][FWEvent]{
      mutate {
        split => { "[rule][FWEvent]" => "," }
        add_tag => "fwevtsda_success"
        add_field => {"[rule][id]" => "%{[rule][FWEvent][0]}"}
        add_field => {"[rule][action]" => "%{[rule][FWEvent][6]}"}
        add_field => {"[interface][name]" => "%{[rule][FWEvent][4]}"}
        add_field => {"[network][transport][id]" => "%{[rule][FWEvent][15]}"}
        add_field => {"[network][transport][name]" => "%{[rule][FWEvent][16]}"}
        add_field => {"[source][ip]" => "%{[rule][FWEvent][18]}"}
        add_field => {"[destination][ip]" => "%{[rule][FWEvent][19]}"}
      }
        
    }


##########  Mapping Certain PFsense fields to ECS so they are searchable, use tagging conditional to simplify logic

# PFSense has some conditional uses for fileds depending on procol
if "fwevtsda_success" in [tags]{
  if [network][transport][name] =~ /^tcp$/ {
    mutate {
      add_field => {"[source][port]" => "%{[rule][FWEvent][20]}"}
      add_field => {"[destination][port]" => "%{[rule][FWEvent][21]}"}
      add_field => {"[network][packet][length]" => "%{[rule][FWEvent][17]}"}
      add_field => {"[network][packet][flags]" => "%{[rule][FWEvent][14]}"}
      add_field => {"[network][transport][flags]" => "%{[rule][FWEvent][23]}"}
      add_field => {"[network][transport][options]" => "%{[rule][FWEvent][28]}"}
    }
  }
  if [network][transport][name] =~ /^udp$/ {
    mutate {
      add_field => {"[source][port]" => "%{[rule][FWEvent][20]}"}
      add_field => {"[destination][port]" => "%{[rule][FWEvent][21]}"}
      add_field => {"[network][packet][length]" => "%{[rule][FWEvent][17]}"}
    }
  }
}
#


} # END ECS field mapping 



######################################################################################################################################
output {

# Comment out if debugging not required ( improves performance marginally and but still allows logstash stdout events to be observed)
  stdout { codec => rubydebug }

################################################## Elastic output section ############################################################

## Uncomment to enable persistance in an elastic search instance of the original data
elasticsearch {
    hosts => ["Your_Elastic_host:9200"]
    index => "Your_Elastic_Indexname"
    cacert => "/etc/logstash/Your_Elastic_host.crt"
    ssl_certificate_verification => false
    ssl => true
    user => "elastic"
    password => "your_Elastic_Secret"
  }
# End of output filter
}